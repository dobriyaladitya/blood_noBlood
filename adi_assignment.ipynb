{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "adi_assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dobriyaladitya/blood_noBlood/blob/master/adi_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L5yCEuy4L_n",
        "colab_type": "text"
      },
      "source": [
        "# Facial blood detection using CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcyY6t-_4jCP",
        "colab_type": "text"
      },
      "source": [
        "Note: Make sure you have python installed in order to work the pip command. The method is implemented using keras, that needs to be pre installed as well. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd31Dkda5V3j",
        "colab_type": "text"
      },
      "source": [
        "Implementation is done in 4 stages:\n",
        "\n",
        "\n",
        "*   Pre-processing images\n",
        "*   Defining model architecture\n",
        "*   Training the model\n",
        "*   Measuring the performance of the model created\n",
        "\n",
        "To do so we first import all necesarry libraries and packages from keras,\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKiVlDmxq-7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Implementing convolutional neural networks\n",
        "\n",
        "\"\"\"\n",
        "!pip install tensorflow\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D, Dropout\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "INPUT_DIR_TRAIN = \"/data/training_set\" #change to location of the folder on drive\n",
        "INPUT_DIR_TEST = \"/data/test_set\" #change to location of the folder on drive\n",
        "NUM_OF_EPOCH = 10\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Osh5jTI38EcJ",
        "colab_type": "text"
      },
      "source": [
        "The next part would be defining a function for preparing the training data, to further enhance accuracy and reduce chances of overfitting we use data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99yV3R63q-7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_training_data():\n",
        "\n",
        "    # shear_range is for randomly applying shearing transformations\n",
        "    # zoom_range is for randomly zooming inside pictures\n",
        "    # horizontal_flip is for randomly flipping half the images horizontallyâ€”relevant when there are no assumptions of horizontal asymmetry\n",
        "    # fill_mode is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift\n",
        "    train_datagen_augmented = ImageDataGenerator(rescale = 1./255, shear_range = 0.1, zoom_range = 0.2, horizontal_flip = True, fill_mode= 'nearest')\n",
        "\n",
        "    train_img_data_gen = ImageDataGenerator(rescale = 1./255)\n",
        "    test_img_data_gen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "    training_set = train_datagen_augmented.flow_from_directory(INPUT_DIR_TRAIN , target_size = (150, 150), batch_size = 32, class_mode = 'binary')\n",
        "    testing_set = test_img_data_gen.flow_from_directory(INPUT_DIR_TRAIN , target_size = (150, 150), batch_size = 32, class_mode = 'binary')\n",
        "    return training_set, testing_set\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4DmQYOOq-7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Displayes the image along with the label. Can be used to verify the input data\n",
        "def show_sample_data_with_labels(training_set, range_vl):\n",
        "    import matplotlib.pyplot as plt\n",
        "    x,y = training_set.next()\n",
        "    for i in range(0,range_vl):\n",
        "        image = x[i]\n",
        "        label = y[i]\n",
        "        print (label)\n",
        "        plt.imshow(image)\n",
        "        plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbDC4sRZ977H",
        "colab_type": "text"
      },
      "source": [
        "Now for the heart of the network, we define the model structure. We use a set of input layers and a hidden and output layer as highlighted in the code below. A brief understanding of the layer types, \n",
        "\n",
        "\n",
        "\n",
        "*   Convolutional layers are image feature detectors, they help the machine identify certain features in an image that help it differentiate\n",
        "*   Pooling layers are used to reduce the size of feature map, making the model more robust without loosing any of the features due to down sampling, we have used max pooling in our implementation\n",
        "*   The flatter layer transfors our 2D array into a vector (1D tensor)\n",
        "*   Dropout is as the word reads, used to drop nodes randomly from a few layers of the network, again to account for overfitting and also reducing training time for each epoch\n",
        "\n",
        "All of the layers have ReLU activation except the output layer which is using sigmoid, this is done to ensure that the final output of the model comes out to a value between 0 and 1, a standard procedure for most classification supervised learning problems\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3uKFXYyq-7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_the_model():\n",
        "    model = Sequential()\n",
        "    # input_shape (image_height, image_width,image_channels)=(150, 150, 3) where 150*150 is the image size and 3 is the RGB elements\n",
        "    model.add(Convolution2D(filters = 32, kernel_size = (3,3), input_shape=(150,150,3), activation = 'relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units = 512, activation = 'relu')) #hidden layer\n",
        "    model.add(Dense(units = 1, activation = 'sigmoid')) #output layer\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bZB1v1AG3Bu",
        "colab_type": "text"
      },
      "source": [
        "A function to plot the graph and return the accuracy and loss of the training as well as validation or testing set,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2esTjvCqq-71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_the_graph(history):\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaqRhUW9HDrt",
        "colab_type": "text"
      },
      "source": [
        "Calling all the functions to execute the model and compile a resulting graph that gives us the loss and accuracy visualisation, "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRG16-eXq-73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepares the training and test data\n",
        "# training_set,test_set = prepare_training_data()\n",
        "training_set, test_set = prepare_training_data()\n",
        "\n",
        "# Defines the model with layers\n",
        "model = define_the_model()\n",
        "\n",
        "# Selects the optimizer, validation function and the metrics\n",
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "model.save('blooded_or_not_2')\n",
        "\n",
        "# Processes in the batches\n",
        "history = model.fit_generator(training_set, steps_per_epoch=100, nb_epoch = NUM_OF_EPOCH, validation_data = test_set, validation_steps = 50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O79ijpamq-79",
        "colab_type": "code",
        "outputId": "bd20452e-fbff-48fc-e64f-b49748a71a31",
        "colab": {}
      },
      "source": [
        "x,y = next(test_set)\n",
        "predictions = model.predict(x)\n",
        "for i in range (0,len(predictions)):\n",
        "    print(i,': ',y[i], '    ', predictions[i])\n",
        "\n",
        "#plot_the_graph(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 :  1.0      [1.]\n",
            "1 :  0.0      [1.]\n",
            "2 :  1.0      [1.]\n",
            "3 :  0.0      [1.]\n",
            "4 :  0.0      [1.]\n",
            "5 :  1.0      [1.]\n",
            "6 :  0.0      [1.]\n",
            "7 :  1.0      [1.]\n",
            "8 :  0.0      [1.]\n",
            "9 :  0.0      [1.]\n",
            "10 :  0.0      [1.]\n",
            "11 :  1.0      [1.]\n",
            "12 :  1.0      [1.]\n",
            "13 :  0.0      [1.]\n",
            "14 :  0.0      [1.]\n",
            "15 :  0.0      [1.]\n",
            "16 :  0.0      [1.]\n",
            "17 :  1.0      [1.]\n",
            "18 :  1.0      [1.]\n",
            "19 :  1.0      [1.]\n",
            "20 :  0.0      [1.]\n",
            "21 :  0.0      [1.]\n",
            "22 :  1.0      [1.]\n",
            "23 :  0.0      [1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgViu3XjHQAf",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1XgH5CkmxbVWffDlRzqehCwhXL95HMwip)\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1jkhG_ijZN6mHA1vGlNqRxSErlPnX-Z__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVTqd-fCICIm",
        "colab_type": "text"
      },
      "source": [
        "As you can see the accuracy of the model increases with the epochs and the loss comes down as we move from 2 to 10 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IP1ZmdJq-8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}